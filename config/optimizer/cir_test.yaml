type: torch.optim.AdamW
param_groups:
  default:
    lr: 1e-4              
    weight_decay: 0.01    
    weight_decay_bias: 0.0
    betas: [0.9, 0.999]   
    eps: 1.0e-8
    # scheduler
    start_lr: 1.0e-6      
    end_lr: 1.0e-5       
  
  backbone:
    lr: ${optimizer.param_groups.default.lr} 
    weight_decay: 0.01
    weight_decay_bias: 0.0
    betas: [0.9, 0.999]
    eps: 1.0e-8
    # scheduler
    start_lr: ${eval:'${optimizer.param_groups.default.start_lr}'}
    end_lr: ${eval:'${optimizer.param_groups.default.end_lr}'}
  
  cross: 
    lr: ${eval:'${optimizer.param_groups.default.lr} * 1.0'} 
    weight_decay: 0.05    # Giảm từ 0.2 xuống 0.05
    weight_decay_bias: 0.0
    betas: [0.9, 0.999]
    eps: 1.0e-8
    # scheduler
    start_lr: ${eval:'${optimizer.param_groups.default.start_lr} * 1.0'}
    end_lr: ${eval:'${optimizer.param_groups.default.end_lr} * 1.0'}
  
  simclr: 
    lr: ${eval:'${optimizer.param_groups.default.lr} * 1.0'}
    weight_decay: 0.05    # Giảm từ 0.2 xuống 0.05
    weight_decay_bias: 0.0
    betas: [0.9, 0.999]
    eps: 1.0e-8
    # scheduler
    start_lr: ${eval:'${optimizer.param_groups.default.start_lr} * 1.0'}
    end_lr: ${eval:'${optimizer.param_groups.default.end_lr} * 1.0'}